# 🤖 Telegram Product Scraper with AI

A robust, production-ready Telegram scraper for extracting product data with AI-powered extraction using Google Gemini.

## 📋 Table of Contents

- [Features](#features)
- [Architecture](#architecture)
- [Installation](#installation)
- [Configuration](#configuration)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Development](#development)
- [Troubleshooting](#troubleshooting)

---

## ✨ Features

### Core Features
- ✅ **AI-Powered Extraction**: Uses Google Gemini API for accurate product data extraction
- ✅ **Automatic Fallback**: Falls back to manual extraction if AI fails
- ✅ **Multi-Channel Support**: Scrapes multiple Telegram channels simultaneously
- ✅ **Media Management**: Downloads and manages product images/videos
- ✅ **Backend Integration**: Sends data to REST API backend
- ✅ **Offline Mode**: Saves data locally when backend is unavailable

### Advanced Features
- 🔄 **3 Operating Modes**: History, Live, and Hybrid
- 🛡️ **Robust Error Handling**: Handles FloodWait, network errors, etc.
- 💾 **Smart Caching**: Caches messages to reduce API calls
- 📦 **Batch Processing**: Processes messages in configurable batches
- 🔍 **Price Extraction**: Intelligently extracts Arabic prices
- 📊 **Detailed Logging**: Color-coded, informative logs
- 🏗️ **Modular Architecture**: Clean, maintainable code structure

---

## 🏛️ Architecture

```
┌─────────────────────────────────────────┐
│         Telegram Scraper                │
├─────────────────────────────────────────┤
│                                         │
│  ┌───────────────────────────────────┐ │
│  │   TelegramProductScraper         │ │
│  │   (Main Controller)              │ │
│  └───────────────┬───────────────────┘ │
│                  │                      │
│     ┌────────────┼────────────┐        │
│     │            │            │        │
│     ▼            ▼            ▼        │
│  ┌─────┐    ┌─────┐      ┌─────┐     │
│  │Gemini│   │Text │      │Price│     │
│  │Extract│  │Extract│    │Extract│    │
│  └─────┘    └─────┘      └─────┘     │
│     │            │            │        │
│     └────────────┴────────────┘        │
│                  │                      │
│                  ▼                      │
│          ┌──────────────┐              │
│          │ ProductData  │              │
│          └──────┬───────┘              │
│                 │                       │
│        ┌────────┴────────┐             │
│        ▼                 ▼             │
│   ┌─────────┐      ┌──────────┐       │
│   │ Media   │      │ Backend  │       │
│   │ Handler │      │ Client   │       │
│   └─────────┘      └──────────┘       │
│                                         │
└─────────────────────────────────────────┘
```

### Components

#### 1. **Extractors**
- `GeminiExtractor`: AI-powered extraction using Gemini
- `TextExtractor`: Manual text parsing
- `PriceExtractor`: Arabic price extraction with regex

#### 2. **Data Models**
- `ProductData`: Complete product information
- `ProductPrice`: Pricing structure
- `Config`: Application configuration

#### 3. **Handlers**
- `MediaHandler`: Downloads and manages media files
- `BackendClient`: API communication
- `FileManager`: File operations

#### 4. **Utilities**
- `Logger`: Color-coded logging
- Error handling with retry logic
- FloodWait protection

---

## 🚀 Installation

### Quick Start (2 minutes)

**Linux/Mac:**
```bash
chmod +x setup.sh
./setup.sh
```

**Windows:**
```bash
setup.bat
```

The setup script will:
- ✅ Check Python version
- ✅ Create virtual environment
- ✅ Install dependencies
- ✅ Create .env file
- ✅ Create necessary directories

### Manual Installation (5 minutes)

```bash
# 1. Clone and setup
git clone <repository-url>
cd telegram-scraper
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 2. Install dependencies
pip install -r requirements.txt

# 3. Configure
cp .env.example .env
nano .env  # Edit with your credentials

# 4. Test Gemini (optional)
python test_gemini.py

# 5. Run!
python scraper.py
```

### Detailed Installation

### Prerequisites
- Python 3.8+
- Telegram API credentials
- Google Gemini API key (optional)

### Steps

1. **Clone the repository**
```bash
git clone <repository-url>
cd telegram-scraper
```

2. **Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Configure environment**
```bash
cp .env.example .env
# Edit .env with your credentials
```

---

## ⚙️ Configuration

### Environment Variables

Create a `.env` file in the project root:

```env
# ============================================
# Telegram Configuration (Required)
# ============================================
TELEGRAM_API_ID=your_api_id
TELEGRAM_API_HASH=your_api_hash
TELEGRAM_PHONE=+201234567890

# ============================================
# Backend Configuration (Optional)
# ============================================
BACKEND_URL=https://your-backend.com/api/products
BACKEND_TOKEN=your_backend_token
TENANT_ID=7

# ============================================
# AI Configuration (Optional)
# ============================================
GEMINI_API_KEY=your_gemini_api_key
GEMINI_MODEL=gemini-1.5-flash

# ============================================
# Scraping Configuration
# ============================================
SCRAPER_MODE=hybrid              # history, live, or hybrid
STOP_DATE=2024-01-01            # Optional: stop scraping at this date
BATCH_SIZE=100                   # Messages per batch
MAX_LOOKBACK=20                  # Max messages to look back for media
MAX_RETRIES=3                    # Retry attempts for downloads
```

### Getting API Keys

#### Telegram API
1. Go to https://my.telegram.org
2. Login with your phone number
3. Go to "API Development Tools"
4. Create a new application
5. Copy `API_ID` and `API_HASH`

#### Gemini API
1. Go to https://makersuite.google.com/app/apikey
2. Create a new API key
3. Copy the key to `.env`

**Test your API key:**
```bash
python test_gemini.py
```

This will:
- ✅ Verify your API key
- 📋 List all available models
- 🧪 Test extraction with sample data
- 💡 Show recommendations

**Note**: Gemini is optional. Without it, the scraper uses manual extraction.

---

## 📖 Usage

### Basic Usage

```bash
# Run in hybrid mode (history + live)
python scraper.py

# Specify mode via environment
SCRAPER_MODE=history python scraper.py
```

### Operating Modes

#### 1. **History Mode**
Scrapes all historical messages from channels.

```bash
SCRAPER_MODE=history python scraper.py
```

**Output**: `products.json`

#### 2. **Live Mode**
Monitors channels for new messages in real-time.

```bash
SCRAPER_MODE=live python scraper.py
```

**Behavior**: Runs indefinitely until interrupted

#### 3. **Hybrid Mode** (Recommended)
Scrapes history first, then switches to live monitoring.

```bash
SCRAPER_MODE=hybrid python scraper.py
```

---

## 📁 Project Structure

```
telegram-scraper/
├── scraper.py              # Main application
├── test_gemini.py          # Test Gemini API
├── setup.sh                # Linux/Mac setup script
├── setup.bat               # Windows setup script
├── requirements.txt        # Python dependencies
├── .env                    # Environment configuration
├── .env.example           # Example configuration
├── README.md              # This file
│
├── downloaded_images/     # Downloaded media (auto-created)
├── scraper_session.session # Telegram session (auto-created)
│
├── products.json          # Scraped products (history mode)
├── offline_products.json  # Products when backend is down
└── failed_products.json   # Products that failed to send
```

---

## 🛠️ Development

### Code Quality

The codebase follows these principles:

1. **SOLID Principles**
   - Single Responsibility: Each class has one job
   - Open/Closed: Easy to extend
   - Dependency Injection: Used throughout

2. **Clean Code**
   - Type hints everywhere
   - Comprehensive docstrings
   - Descriptive variable names

3. **Error Handling**
   - Try-catch blocks with specific exceptions
   - Graceful degradation
   - Detailed error logging

### Adding New Channels

Edit the `CHANNELS` dictionary in `scraper.py`:

```python
CHANNELS = {
    'https://t.me/+YOUR_CHANNEL_ID': 'Category Name',
    # Add more channels here
}
```

### Customizing Extraction

#### Add Custom Price Pattern
```python
class PriceExtractor:
    PRICE_PATTERNS = [
        # Add your pattern here
        r'your_pattern_(\d+(?:\.\d+)?)',
    ]
```

#### Customize Gemini Prompt
```python
class GeminiExtractor:
    def _build_prompt(self, text: str, channel_name: str) -> str:
        # Modify prompt here
        return f"""Your custom prompt: {text}"""
```

---

## 🐛 Troubleshooting

### Common Issues

#### 1. **FloodWait Errors**
```
⏳ FloodWait: waiting 300s...
```
**Solution**: The scraper automatically handles this. Just wait.

#### 2. **Session Expired**
```
❌ Failed to connect: Session expired
```
**Solution**: Delete `scraper_session.session` and run again.

#### 3. **No Products Extracted**
```
⚠️ Invalid product skipped
```
**Causes**:
- No media in message
- Price not detected
- Empty product name

**Solution**: Check message format or enable Gemini API.

#### 4. **Gemini API Errors**

**Error: Model not found**
```
models/gemini-1.5-flash is not found for API version v1
```
**Solution**:
```bash
# Run scraper once to list available models
python scraper.py

# Or manually test:
curl "https://generativelanguage.googleapis.com/v1/models?key=YOUR_KEY"

# Update .env with correct model:
GEMINI_MODEL=gemini-1.5-flash-latest
```

**Error: Quota exceeded**
```
⚠️ Gemini API error 429: Quota exceeded
```
**Solution**:
- Wait for quota reset (usually resets daily)
- Scraper automatically falls back to manual extraction
- Free tier: 60 requests/minute, 1500 requests/day

#### 5. **Backend Connection Failed**
```
❌ Failed to send product: Connection timeout
```
**Solution**:
- Check `BACKEND_URL` in `.env`
- Products are saved to `failed_products.json`

### Debug Mode

Enable detailed logging:

```python
# In scraper.py, add at the top:
import logging
logging.basicConfig(level=logging.DEBUG)
```

---

## 📊 Output Formats

### Product JSON Structure

```json
{
  "unique_id": "123456_789",
  "channel_id": 123456,
  "message_id": 789,
  "timestamp": "2024-10-25T10:30:00+00:00",
  "channel_name": "أدوات منزلية",
  "name": "Product Name",
  "short_description": "Short desc",
  "description": "Full description",
  "images": [
    "downloaded_images/product_123456_789_0.jpg"
  ],
  "prices": {
    "current_price": 150.0,
    "old_price": 200.0
  },
  "extraction_method": "✨ Gemini AI"
}
```

---

## 🔒 Security

- Never commit `.env` file
- Keep API keys secure
- Use environment variables for sensitive data
- Review permissions before joining channels

---

## 📈 Performance Tips

1. **Batch Size**: Increase for faster scraping
   ```env
   BATCH_SIZE=200
   ```

2. **Parallel Processing**: Modify code to process channels in parallel

3. **Caching**: Messages are automatically cached

4. **Media**: Only supported formats are downloaded

---

## 🤝 Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open Pull Request

---

## 📝 License

[Your License Here]

---

## 🙏 Acknowledgments

- Telethon for Telegram API
- Google Gemini for AI extraction
- aiohttp for async HTTP

---

## 📞 Support

For issues and questions:
- Open an issue on GitHub
- Check existing issues first
- Provide logs and configuration (without sensitive data)

---

**Made with ❤️ for efficient product scraping**
