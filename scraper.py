import aiohttp
import asyncio
import json
import os
import re
from datetime import datetime
from datetime import datetime, timezone
from dotenv import load_dotenv
from telethon import TelegramClient, events
from telethon.tl.types import MessageMediaPhoto
from typing import List, Dict, Optional

load_dotenv()

print("ğŸš€ Scraper started...", flush=True)

# Telegram API credentials
API_ID = os.getenv('TELEGRAM_API_ID')
API_HASH = os.getenv('TELEGRAM_API_HASH')
PHONE = os.getenv('TELEGRAM_PHONE')
BACKEND_URL = os.getenv('BACKEND_URL', '')

print("ENV DEBUG:", API_ID, API_HASH, PHONE, flush=True)

# Ù‚Ù†ÙˆØ§Øª Ø§Ù„ØªÙ„ÙŠØ¬Ø±Ø§Ù…
CHANNELS = {
    'https://t.me/+VAkpot4taw_v9n2p': 'Ø§Ø¯ÙˆØ§Øª Ù…Ù†Ø²Ù„ÙŠØ©',
    'https://t.me/+UbRrLCJUETxcZmWJ': 'Ù„Ø¹Ø¨ Ø§Ø·ÙØ§Ù„',
    'https://t.me/+TQHOHpqeFZ4a2Lmp': 'Ù…Ø³ØªØ­Ø¶Ø±Ø§Øª ØªØ¬Ù…ÙŠÙ„',
    'https://t.me/+T1hjkvhugV4GxRYD': 'Ù…Ù„Ø§Ø¨Ø³ Ø¯Ø§Ø®Ù„ÙŠØ©',
    'https://t.me/+Tx6OTiWMi6WS4Y2j': 'Ù…ÙØ±ÙˆØ´Ø§Øª',
    'https://t.me/+Sbbi6_lLOI2_wP41': 'Ø´Ø±Ø§Ø¨Ø§Øª',
    'https://t.me/+R5rjl2_-KV3GWYAr': 'Ù‡ÙˆÙ… ÙˆÙŠØ± ÙˆÙ„Ø§Ù†Ø¬ÙŠØ±ÙŠ',
    'https://t.me/+WQ-FJCIwbKrcw2qC': 'Ù…Ù„Ø§Ø¨Ø³ Ø§Ø·ÙØ§Ù„',
    'https://t.me/+SSyWF7Ya89yPm2_V': 'Ø§ÙƒØ³Ø³ÙˆØ§Ø±Ø§Øª',
    'https://t.me/+TsQpYNpBaoRkz-8h': 'ØªØµÙÙŠØ§Øª',
}


class TelegramProductScraper:
    def __init__(self):
        self.client = TelegramClient('scraper_session', API_ID, API_HASH)
        self.products = []

    def extract_price(self, text: str) -> Dict[str, Optional[float]]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ù…Ù† Ø§Ù„Ù†Øµ ÙˆØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ù‚Ù„ ÙƒØ§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ"""
        # Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ù…ÙƒÙ†Ø© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ø¹Ø±
        price_patterns = [
            r'(\d+(?:\.\d+)?)\s*(?:Ø¬Ù†ÙŠÙ‡|Ø¬\.Ù…|LE)',
            r'Ø§Ù„Ø³Ø¹Ø±[:\s]+(\d+(?:\.\d+)?)',
            r'Ø¨Ø³Ø¹Ø±[:\s]+(\d+(?:\.\d+)?)',
            r'Ø¨Ù€(\d+(?:\.\d+)?)',
            r'(\d+(?:\.\d+)?)\s*Ø¬',  # Ø²ÙŠ 199Ø¬ Ø£Ùˆ 220Ø¬
        ]

        all_prices = set()

        for pattern in price_patterns:
            for match in re.findall(pattern, text):
                try:
                    all_prices.add(float(match))
                except ValueError:
                    pass

        prices = {
            'current_price': None,
            'old_price': None
        }

        if all_prices:
            prices['current_price'] = min(all_prices)
            if len(all_prices) > 1:
                prices['old_price'] = max(all_prices)

        # fallback Ø¨Ø³ÙŠØ· Ù„Ùˆ Ù…ÙÙŠØ´ Ø£ÙŠ Ù†Ù…Ø· Ù…Ø¹Ø±ÙˆÙ
        if not prices['current_price']:
            match = re.search(r'(\d+(?:\.\d+)?)', text)
            if match:
                prices['current_price'] = float(match.group(1))

        return prices

    async def download_image(self, message, index: int) -> Optional[str]:
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©/Ø§Ù„ÙÙŠØ¯ÙŠÙˆ/Ø§Ù„Ù…Ø³ØªÙ†Ø¯ ÙˆØ­ÙØ¸Ù‡ Ø¨Ø§Ù„Ø§Ù…ØªØ¯Ø§Ø¯ Ø§Ù„ØµØ­ÙŠØ­"""
        try:
            media_dir = 'downloaded_images'
            os.makedirs(media_dir, exist_ok=True)

            ext = 'unknown'

            # Ø§Ù„ØµÙˆØ±
            if getattr(message.media, 'photo', None):
                ext = 'jpg'
            # Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø£Ùˆ Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª
            elif getattr(message.media, 'document', None) and hasattr(message.media.document, 'mime_type'):
                mime = message.media.document.mime_type
                if 'png' in mime:
                    ext = 'png'
                elif 'gif' in mime:
                    ext = 'gif'
                elif 'jpeg' in mime:
                    ext = 'jpg'
                elif 'mp4' in mime:
                    ext = 'mp4'
                elif 'webp' in mime:
                    ext = 'webp'
                else:
                    ext = mime.split('/')[-1]  # fallback Ù„Ø£ÙŠ Ù†ÙˆØ¹ Ø¢Ø®Ø±

            filename = f"{media_dir}/product_{message.chat_id}_{message.id}_{index}.{ext}"

            if os.path.exists(filename):
                print(f"ğŸŸ¡ Skipping download (already exists): {filename}")
                return filename

            await message.download_media(file=filename)
            print(f"ğŸ“¥ Downloaded new media: {filename}")
            return filename

        except Exception as e:
            print(f"Error downloading media: {e}")
            return None

    async def send_to_backend(self, product_data: Dict):
        """Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ù€ Backend Ù…Ø¹ Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±/Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª ÙƒÙ…Ù„ÙØ§Øª"""
        if not BACKEND_URL:
            print("âš ï¸ BACKEND_URL ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­Ù„ÙŠÙ‹Ø§.")
            offline_file = 'offline_products.json'
            data = []
            if os.path.exists(offline_file):
                with open(offline_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
            if any(p['unique_id'] == product_data['unique_id'] for p in data):
                print(f"â­ï¸ Product already exists locally: {product_data['unique_id']}")
            else:
                data.append(product_data)
                with open(offline_file, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
                print(f"ğŸ’¾ Product saved locally: {product_data['name']}")
            return

        try:
            async with aiohttp.ClientSession() as session:
                form = aiohttp.FormData()

                # Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù†ØµÙŠØ©
                form.add_field('variants[0][sku]', product_data.get('unique_id', ''))
                form.add_field('variants[0][barcode]', product_data.get('unique_id', ''))
                form.add_field('variants[0][stock]', '10')
                form.add_field('name[ar]', product_data.get('name', ''))
                form.add_field('name[en]', product_data.get('name', ''))
                form.add_field('description[ar]', product_data.get('description', ''))
                form.add_field('description[en]', product_data.get('description', ''))
                form.add_field('short_description[ar]', product_data.get('description', ''))
                form.add_field('short_description[en]', product_data.get('description', ''))
                form.add_field('category_name', product_data.get('channel_name', ''))

                # Ø§Ù„Ø£Ø³Ø¹Ø§Ø±
                prices = product_data.get('prices', {})
                if prices.get('old_price'):
                    form.add_field('variants[0][price]', str(prices['old_price']))
                    form.add_field('variants[0][discount]', str(prices['current_price']))
                else:
                    form.add_field('variants[0][price]', str(prices.get('current_price') or 0))

                # Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±/Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª ÙƒÙ…Ù„ÙØ§Øª
                for media_path in product_data.get('images', []):
                    if os.path.exists(media_path):
                        # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…ÙŠØ¯ÙŠØ§ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù…ØªØ¯Ø§Ø¯ Ø§Ù„Ù…Ù„Ù
                        ext = os.path.splitext(media_path)[1].lower()
                        if ext in ['.jpg', '.jpeg']:
                            content_type = 'image/jpeg'
                        elif ext == '.png':
                            content_type = 'image/png'
                        elif ext == '.gif':
                            content_type = 'image/gif'
                        elif ext == '.webp':
                            content_type = 'image/webp'
                        elif ext == '.mp4':
                            content_type = 'video/mp4'
                        else:
                            content_type = None

                        # Ø¥Ø°Ø§ Ø¹Ø§ÙŠØ² ØªØªØ®Ø·Ù‰ Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª
                        if content_type is None or content_type.startswith('video/'):
                            print(f"âš ï¸ Skipping media (unsupported type): {media_path}")
                            continue

                        form.add_field(
                            'variants[0][images][]',
                            open(media_path, 'rb'),
                            filename=os.path.basename(media_path),
                            content_type=content_type
                        )

                headers = {
                    'Authorization': f"Bearer {os.getenv('BACKEND_TOKEN', '')}",  # Ù‡Ù†Ø§ ØªØ­Ø· Ø§Ù„ØªÙˆÙƒÙ†
                    'Accept': "application/json",
                    'Tenant-Id': "7",  # "https://www.bepucepehutozy.me"
                    'Referer': "https://rosyland.obranchy.com",
                }

                # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                async with session.post(BACKEND_URL, data=form, headers=headers) as resp:
                    resp_text = await resp.text()
                    if resp.status in [200, 201]:
                        print(f"âœ… Product sent successfully: {product_data['name']}")
                    else:
                        print(f"âŒ Failed to send product: {resp.status}")
                        print(f"ğŸ§¾ Response: {resp_text}")

        except Exception as e:
            print(f"Error sending to backend: {e}")

    async def process_message(self, message, channel_name: str = None):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø³Ø§Ù„Ø© ÙˆØ§Ø­Ø¯Ø©"""
        if not message.text:
            return  # Ù„Ø§Ø²Ù… ÙŠÙƒÙˆÙ† ÙÙŠÙ‡ Ù†Øµ

        # Ù†ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø£ÙŠ Ù…ÙŠØ¯ÙŠØ§ (ØµÙˆØ±Ø© Ø£Ùˆ ÙÙŠØ¯ÙŠÙˆ Ø£Ùˆ document)
        if not (getattr(message.media, 'photo', None) or
                getattr(message.media, 'document', None) or
                getattr(message.media, 'video', None)):
            print(f"âš ï¸ Skipping message without media: {message.text[:50]}...")
            return

        unique_id = f"{message.chat_id}_{message.id}"

        product = {
            'unique_id': unique_id,
            'channel_id': message.chat_id,
            'message_id': message.id,
            'timestamp': message.date.isoformat(),
            'channel_name': channel_name,
            'description': message.text or '',
            'images': [],
            'prices': {'current_price': None, 'old_price': None}
        }

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø§Ø³Ù…
        text = message.text.strip()
        lines = text.splitlines()
        if lines:
            first_line = lines[0].strip()
            if re.search(r'\bÙˆØµÙ„\b', first_line):
                name = lines[1].strip() if len(lines) > 1 else first_line
            else:
                name = first_line
        else:
            name = ""
        product['name'] = name

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø³Ø¹Ø§Ø±
        product['prices'] = self.extract_price(message.text)

        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙŠØ¯ÙŠØ§ (ØµÙˆØ±Ø© Ø£Ùˆ ÙÙŠØ¯ÙŠÙˆ Ø£Ùˆ document)
        media_path = await self.download_image(message, 0)
        if media_path:
            product['images'].append(media_path)

        # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù…Ù†ØªØ¬ Ù„Ùˆ Ù…Ø§ÙÙŠØ´ Ù…ÙŠØ¯ÙŠØ§ ÙØ¹Ù„ÙŠØ§Ù‹
        if not product['images']:
            print(f"âŒ Product skipped (no media downloaded): {product['name']}")
            return

        # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­Ù„ÙŠØ§Ù‹
        self.products.append(product)

        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù†ØªØ¬ Ù„Ù„Ù€ backend
        await self.send_to_backend(product)

        print(f"ğŸ“¦ Product processed: {product['description'][:50]}... | Price: {product['prices']['current_price']}")

    async def scrape_channel_history(self, channel_link: str):
        """Ø³ÙƒØ±Ø§Ø¨ÙŠÙ†Ø¬ ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚Ù†Ø§Ø© Ø­ØªÙ‰ ØªØ§Ø±ÙŠØ® Ù…Ø­Ø¯Ø¯"""
        try:
            stop_date_str = os.getenv('STOP_DATE', '')
            stop_date = None
            if stop_date_str:
                try:
                    stop_date = datetime.strptime(stop_date_str, '%Y-%m-%d').replace(tzinfo=timezone.utc)
                    print(f"ğŸ“… Stop date set to: {stop_date.date()}")
                except ValueError:
                    print("âš ï¸ ØªÙ†Ø¨ÙŠÙ‡: ØªÙ†Ø³ÙŠÙ‚ STOP_DATE ØºÙŠØ± ØµØ­ÙŠØ­! Ø§Ø³ØªØ®Ø¯Ù… YYYY-MM-DD.")

            # Ø§Ø³Ù… Ø§Ù„Ù‚Ù†Ø§Ø© Ø§Ù„Ù…Ø®ØµØµ Ù…Ù† Ø§Ù„Ù€ dict
            channel_name = CHANNELS.get(channel_link, 'Ù‚Ù†Ø§Ø© ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ©')

            # Ø§Ù„Ø§Ù†Ø¶Ù…Ø§Ù… Ù„Ù„Ù‚Ù†Ø§Ø©
            entity = await self.client.get_entity(channel_link)
            print(f"ğŸ” Scraping channel: {entity.title} ({channel_name})")

            # Ø¬Ù„Ø¨ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„
            async for message in self.client.iter_messages(entity):
                if stop_date and message.date < stop_date:
                    print(f"â¹ï¸ Stopped at {message.date}")
                    break

                # Ù†Ù…Ø±Ø± Ø§Ø³Ù… Ø§Ù„Ù‚Ù†Ø§Ø© Ù„Ù„Ù…Ù†ØªØ¬
                await self.process_message(message, channel_name)
                await asyncio.sleep(0.5)

        except Exception as e:
            print(f"Error scraping channel {channel_link}: {e}")

    async def start_live_monitoring(self):
        """Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù…Ø¨Ø§Ø´Ø±Ø©"""

        @self.client.on(events.NewMessage(chats=CHANNELS))
        async def handler(event):
            print(f"ğŸ†• New message received!")
            await self.process_message(event.message)

        print("ğŸ‘€ Monitoring channels for new messages...")
        await self.client.run_until_disconnected()

    async def run(self, mode='history'):
        """ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙƒØ±Ø§Ø¨Ø±"""
        await self.client.start(phone=PHONE)
        print("âœ… Connected to Telegram")

        if mode == 'history':
            # Ø³ÙƒØ±Ø§Ø¨ÙŠÙ†Ø¬ Ø§Ù„ØªØ§Ø±ÙŠØ® ÙÙ‚Ø·
            for channel in CHANNELS:
                await self.scrape_channel_history(channel)

            with open('products.json', 'w', encoding='utf-8') as f:
                json.dump(self.products, f, ensure_ascii=False, indent=2)

            print(f"\nâœ… Scraped {len(self.products)} products")
            print("ğŸ“ Data saved to products.json")

        elif mode == 'live':
            # Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø© ÙÙ‚Ø·
            await self.start_live_monitoring()

        elif mode == 'hybrid':
            # ğŸŒ€ Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ù‡Ø¬ÙŠÙ†: Ø§Ù„ØªØ§Ø±ÙŠØ® Ø«Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©
            print("ğŸŒ€ Hybrid mode: Scraping history first, then monitoring live...")

            for channel in CHANNELS:
                await self.scrape_channel_history(channel)

            print(f"\nâœ… Finished scraping history ({len(self.products)} products).")
            print("ğŸ‘€ Now switching to live monitoring...\n")

            await self.start_live_monitoring()


# Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
if __name__ == '__main__':
    scraper = TelegramProductScraper()

    # Ø§Ø®ØªØ± Ø§Ù„ÙˆØ¶Ø¹:
    # 'history' - Ù„Ø³ÙƒØ±Ø§Ø¨ÙŠÙ†Ø¬ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
    # 'live' - Ù„Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø© Ù„Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©

    asyncio.run(scraper.run(mode='hybrid'))
