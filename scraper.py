import aiohttp
import asyncio
import json
import os
import re
from datetime import datetime
from datetime import datetime, timezone
from dotenv import load_dotenv
from telethon import TelegramClient, events
from telethon.tl.types import MessageMediaPhoto
from typing import List, Dict, Optional

load_dotenv()

print("ğŸš€ Scraper started...", flush=True)

# Telegram API credentials
API_ID = os.getenv('TELEGRAM_API_ID')
API_HASH = os.getenv('TELEGRAM_API_HASH')
PHONE = os.getenv('TELEGRAM_PHONE')
BACKEND_URL = os.getenv('BACKEND_URL', '')

print("ENV DEBUG:", API_ID, API_HASH, PHONE, flush=True)

# Ù‚Ù†ÙˆØ§Øª Ø§Ù„ØªÙ„ÙŠØ¬Ø±Ø§Ù…
CHANNELS = {
    'https://t.me/+VAkpot4taw_v9n2p': 'Ø§Ø¯ÙˆØ§Øª Ù…Ù†Ø²Ù„ÙŠØ©',
    'https://t.me/+UbRrLCJUETxcZmWJ': 'Ù„Ø¹Ø¨ Ø§Ø·ÙØ§Ù„',
    'https://t.me/+TQHOHpqeFZ4a2Lmp': 'Ù…Ø³ØªØ­Ø¶Ø±Ø§Øª ØªØ¬Ù…ÙŠÙ„',
    'https://t.me/+T1hjkvhugV4GxRYD': 'Ù…Ù„Ø§Ø¨Ø³ Ø¯Ø§Ø®Ù„ÙŠØ©',
    'https://t.me/+Tx6OTiWMi6WS4Y2j': 'Ù…ÙØ±ÙˆØ´Ø§Øª',
    'https://t.me/+Sbbi6_lLOI2_wP41': 'Ø´Ø±Ø§Ø¨Ø§Øª',
    'https://t.me/+R5rjl2_-KV3GWYAr': 'Ù‡ÙˆÙ… ÙˆÙŠØ± ÙˆÙ„Ø§Ù†Ø¬ÙŠØ±ÙŠ',
    'https://t.me/+WQ-FJCIwbKrcw2qC': 'Ù…Ù„Ø§Ø¨Ø³ Ø§Ø·ÙØ§Ù„',
    'https://t.me/+SSyWF7Ya89yPm2_V': 'Ø§ÙƒØ³Ø³ÙˆØ§Ø±Ø§Øª',
    'https://t.me/+TsQpYNpBaoRkz-8h': 'ØªØµÙÙŠØ§Øª',
}


class TelegramProductScraper:
    def __init__(self):
        self.client = TelegramClient('scraper_session', API_ID, API_HASH)
        self.products = []

    def extract_price(self, text: str) -> Dict[str, Optional[float]]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ø¹Ø± Ù…Ù† Ø§Ù„Ù†Øµ"""
        price_patterns = [
            r'(\d+(?:\.\d+)?)\s*Ø¬Ù†ÙŠÙ‡',
            r'(\d+(?:\.\d+)?)\s*Ø¬\.Ù…',
            r'(\d+(?:\.\d+)?)\s*LE',
            r'Ø§Ù„Ø³Ø¹Ø±[:\s]+(\d+(?:\.\d+)?)',
            r'Ø¨Ø³Ø¹Ø±[:\s]+(\d+(?:\.\d+)?)',
            r'Ø¨Ø¯(?:Ù„Ø§Ù‹|Ù„Ø§)\s+Ù…Ù†\s+(\d+(?:\.\d+)?)',
        ]

        prices = {
            'current_price': None,
            'old_price': None
        }

        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† "Ø¨Ø¯Ù„Ø§ Ù…Ù†" Ù„Ù„Ø³Ø¹Ø± Ø§Ù„Ù‚Ø¯ÙŠÙ…
        old_price_match = re.search(r'Ø¨Ø¯(?:Ù„Ø§Ù‹|Ù„Ø§)\s+Ù…Ù†\s+(\d+(?:\.\d+)?)', text)
        if old_price_match:
            prices['old_price'] = float(old_price_match.group(1))

        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ
        for pattern in price_patterns:
            match = re.search(pattern, text)
            if match and 'Ø¨Ø¯Ù„Ø§ Ù…Ù†' not in pattern:
                prices['current_price'] = float(match.group(1))
                break

        return prices

    async def download_image(self, message, index: int) -> Optional[str]:
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© ÙˆØ­ÙØ¸Ù‡Ø§ Ù…Ø­Ù„ÙŠØ§Ù‹ (Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯Ù‡Ø§ Ù…Ø³Ø¨Ù‚Ø§Ù‹)"""
        try:
            photo_dir = 'downloaded_images'
            os.makedirs(photo_dir, exist_ok=True)

            filename = f"{photo_dir}/product_{message.chat_id}_{message.id}_{index}.jpg"

            # âœ… Ù„Ùˆ Ø§Ù„ØµÙˆØ±Ø© Ù…ØªØ­Ù…Ù„Ø© Ù‚Ø¨Ù„ ÙƒØ¯Ù‡ØŒ Ù†ØªØ®Ø·Ù‰ Ø§Ù„ØªØ­Ù…ÙŠÙ„
            if os.path.exists(filename):
                print(f"ğŸŸ¡ Skipping download (already exists): {filename}")
                return filename

            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ù…Ù† ØªÙ„ÙŠØ¬Ø±Ø§Ù…
            await message.download_media(file=filename)
            print(f"ğŸ“¥ Downloaded new image: {filename}")
            return filename

        except Exception as e:
            print(f"Error downloading image: {e}")
            return None

    async def send_to_backend(self, product_data: Dict):
        """Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ù€ Backend Ø£Ùˆ Ø­ÙØ¸Ù‡Ø§ Ù…Ø­Ù„ÙŠÙ‹Ø§ Ù„Ùˆ BACKEND_URL ÙØ§Ø¶ÙŠ"""
        # âœ… Ù„Ùˆ Ø§Ù„Ù€ BACKEND_URL ÙØ§Ø¶ÙŠ â†’ Ù†Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­Ù„ÙŠÙ‹Ø§ Ø¨Ø¯Ù„ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„
        if not BACKEND_URL:
            print("âš ï¸ BACKEND_URL ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ù…Ù„Ù .env â€” Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ offline_products.json Ø¨Ø¯Ù„ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„.")
            try:
                offline_file = 'offline_products.json'

                # Ù„Ùˆ Ø§Ù„Ù…Ù„Ù Ù…ÙˆØ¬ÙˆØ¯ØŒ Ù†Ù‚Ø±Ø£ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø­Ø§Ù„ÙŠ
                if os.path.exists(offline_file):
                    with open(offline_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                else:
                    data = []

                # ğŸ§  ØªØ­Ù‚Ù‚ Ø¥Ù† Ø§Ù„Ù…Ù†ØªØ¬ Ù…Ø´ Ù…ÙƒØ±Ø± Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø¶Ø§ÙØ©
                if any(p['unique_id'] == product_data['unique_id'] for p in data):
                    print(f"â­ï¸ Product already exists locally: {product_data['unique_id']}")
                else:
                    data.append(product_data)
                    with open(offline_file, 'w', encoding='utf-8') as f:
                        json.dump(data, f, ensure_ascii=False, indent=2)
                    print(f"ğŸ’¾ Product saved locally: {product_data['description'][:50]}...")

            except Exception as e:
                print(f"Error saving offline product: {e}")
            return

        # âœ… Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø¹Ø§Ø¯ÙŠØ©: Ø¥Ø±Ø³Ø§Ù„ Ù„Ù„Ù€ Backend
        try:
            async with aiohttp.ClientSession() as session:
                # Ø±ÙØ¹ Ø§Ù„ØµÙˆØ± Ø£ÙˆÙ„Ø§Ù‹
                image_urls = []
                for image_path in product_data.get('images', []):
                    if os.path.exists(image_path):
                        with open(image_path, 'rb') as f:
                            form = aiohttp.FormData()
                            form.add_field('file', f, filename=os.path.basename(image_path))

                            async with session.post(f"{BACKEND_URL}/upload", data=form) as resp:
                                resp_text = await resp.text()
                                if resp.status == 200:
                                    result = await resp.json()
                                    image_urls.append(result.get('url'))
                                else:
                                    print(f"âš ï¸ Upload failed ({resp.status}) for {image_path}")
                                    print(f"ğŸ§¾ Response: {resp_text}")

                # ØªØ¬Ù‡ÙŠØ² Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†ØªØ¬ Ù„Ù„Ø¥Ø±Ø³Ø§Ù„
                product_data['image_urls'] = image_urls
                del product_data['images']

                # ğŸŸ¡ Ø§Ø·Ø¨Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù„ÙŠ Ù‡ØªØªØ¨Ø¹Øª Ù„Ù„Ù€ backend
                print("\nğŸ“¤ Sending product to backend:")
                print(json.dumps(product_data, ensure_ascii=False, indent=2))

                # Ø¥Ø±Ø³Ø§Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†ØªØ¬
                async with session.post(BACKEND_URL, json=product_data) as resp:
                    resp_text = await resp.text()
                    if resp.status == 201:
                        print(f"âœ… Product sent successfully: {product_data['description'][:50]}...")
                    else:
                        print(f"âŒ Failed to send product: {resp.status}")
                        print(f"ğŸ§¾ Response: {resp_text}")

        except Exception as e:
            print(f"Error sending to backend: {e}")

    async def process_message(self, message, channel_name: str = None):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø³Ø§Ù„Ø© ÙˆØ§Ø­Ø¯Ø©"""
        if not message.text or not message.media:
            return

        unique_id = f"{message.chat_id}_{message.id}"

        product = {
            'unique_id': unique_id,
            'channel_id': message.chat_id,
            'message_id': message.id,
            'timestamp': message.date.isoformat(),
            'channel_name': channel_name,  # ğŸŸ¢ Ù‡Ù†Ø§ Ø¨ÙŠØªØ¶Ø§Ù Ø§Ø³Ù… Ø§Ù„Ù‚Ù†Ø§Ø©
            'description': message.text or '',
            'images': [],
            'prices': {'current_price': None, 'old_price': None}
        }

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø³Ø¹Ø§Ø±
        if message.text:
            product['prices'] = self.extract_price(message.text)

        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±
        if message.media:
            if isinstance(message.media, MessageMediaPhoto):
                image_path = await self.download_image(message, 0)
                if image_path:
                    product['images'].append(image_path)
            elif hasattr(message.media, 'photo'):
                image_path = await self.download_image(message, 0)
                if image_path:
                    product['images'].append(image_path)

        # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­Ù„ÙŠØ§Ù‹
        self.products.append(product)

        # Ø¥Ø±Ø³Ø§Ù„ Ø£Ùˆ Ø­ÙØ¸ Ø§Ù„Ù…Ù†ØªØ¬
        await self.send_to_backend(product)

        print(f"ğŸ“¦ Product processed: {product['description'][:50]}... | Price: {product['prices']['current_price']}")

    async def scrape_channel_history(self, channel_link: str):
        """Ø³ÙƒØ±Ø§Ø¨ÙŠÙ†Ø¬ ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚Ù†Ø§Ø© Ø­ØªÙ‰ ØªØ§Ø±ÙŠØ® Ù…Ø­Ø¯Ø¯"""
        try:
            stop_date_str = os.getenv('STOP_DATE', '')
            stop_date = None
            if stop_date_str:
                try:
                    stop_date = datetime.strptime(stop_date_str, '%Y-%m-%d').replace(tzinfo=timezone.utc)
                    print(f"ğŸ“… Stop date set to: {stop_date.date()}")
                except ValueError:
                    print("âš ï¸ ØªÙ†Ø¨ÙŠÙ‡: ØªÙ†Ø³ÙŠÙ‚ STOP_DATE ØºÙŠØ± ØµØ­ÙŠØ­! Ø§Ø³ØªØ®Ø¯Ù… YYYY-MM-DD.")

            # Ø§Ø³Ù… Ø§Ù„Ù‚Ù†Ø§Ø© Ø§Ù„Ù…Ø®ØµØµ Ù…Ù† Ø§Ù„Ù€ dict
            channel_name = CHANNELS.get(channel_link, 'Ù‚Ù†Ø§Ø© ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ©')

            # Ø§Ù„Ø§Ù†Ø¶Ù…Ø§Ù… Ù„Ù„Ù‚Ù†Ø§Ø©
            entity = await self.client.get_entity(channel_link)
            print(f"ğŸ” Scraping channel: {entity.title} ({channel_name})")

            # Ø¬Ù„Ø¨ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„
            async for message in self.client.iter_messages(entity):
                if stop_date and message.date < stop_date:
                    print(f"â¹ï¸ Stopped at {message.date}")
                    break

                # Ù†Ù…Ø±Ø± Ø§Ø³Ù… Ø§Ù„Ù‚Ù†Ø§Ø© Ù„Ù„Ù…Ù†ØªØ¬
                await self.process_message(message, channel_name)
                await asyncio.sleep(0.5)

        except Exception as e:
            print(f"Error scraping channel {channel_link}: {e}")

    async def start_live_monitoring(self):
        """Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù…Ø¨Ø§Ø´Ø±Ø©"""

        @self.client.on(events.NewMessage(chats=CHANNELS))
        async def handler(event):
            print(f"ğŸ†• New message received!")
            await self.process_message(event.message)

        print("ğŸ‘€ Monitoring channels for new messages...")
        await self.client.run_until_disconnected()

    async def run(self, mode='history'):
        """ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙƒØ±Ø§Ø¨Ø±"""
        await self.client.start(phone=PHONE)
        print("âœ… Connected to Telegram")

        if mode == 'history':
            # Ø³ÙƒØ±Ø§Ø¨ÙŠÙ†Ø¬ Ø§Ù„ØªØ§Ø±ÙŠØ®
            for channel in CHANNELS:
                await self.scrape_channel_history(channel)

            # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ù…Ù„Ù JSON
            with open('products.json', 'w', encoding='utf-8') as f:
                json.dump(self.products, f, ensure_ascii=False, indent=2)

            print(f"\nâœ… Scraped {len(self.products)} products")
            print("ğŸ“ Data saved to products.json")

        elif mode == 'live':
            # Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©
            await self.start_live_monitoring()


# Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
if __name__ == '__main__':
    scraper = TelegramProductScraper()

    # Ø§Ø®ØªØ± Ø§Ù„ÙˆØ¶Ø¹:
    # 'history' - Ù„Ø³ÙƒØ±Ø§Ø¨ÙŠÙ†Ø¬ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
    # 'live' - Ù„Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø© Ù„Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©

    asyncio.run(scraper.run(mode='history'))
    # asyncio.run(scraper.run(mode='live'))
